# BloomWeaver - KI Wissensdatenbank Plattform

## ðŸŒ Projektbeschreibung

BloomWeaver ist eine hochskalierbare, serverlose Plattform zur Verwaltung von Wissensdatenbanken mit KI-UnterstÃ¼tzung. Dokumente und Inhalte werden verarbeitet, vektorisiert und in Pinecone gespeichert, um schnelle semantische Suchen und KI-gestÃ¼tzte Antworten zu ermÃ¶glichen.

Dieses Projekt wird als Solo-Projekt von Dennis Diepolder entwickelt.

---

# ðŸ“Š Systemarchitektur

### Frontend

- **Astro** Framework fÃ¼r statische Seiten.
- **Clerk** fÃ¼r User Authentication.
- **Hosting** Ã¼ber **AWS S3** + **CloudFront**.
- **Domain Management** Ã¼ber **Route53**.
- **SSL** Ã¼ber **ACM Zertifikate**.
- **Uploader und Dateieditor** im Admin Dashboard, der Dateien verarbeitet und automatisch an die Webhook Ã¼bermittelt.
- **Datenbank-Editor** im Admin Dashboard, der gehashte EintrÃ¤ge automatisch an die Webhook sendet.

### Backend

- **Sprache:** Alles in **Go**, auÃŸer dem Embedding Worker, der in **Python** entwickelt ist.
- **API Gateway** fÃ¼r Webhook Empfang.
- **Webhook Lambda**:
  - Weiterleitung aller Operationen (INSERT/UPDATE/DELETE) Ã¼ber SQS Queuing
- **SQS Queues**:
  - ChangeQueue
  - CreateQueue
  - UpdateQueue
  - DeleteQueue
  - DeadLetterQueue (fÃ¼r Fehlerbehandlung)
- **Embedding Worker** (FastAPI Python Service):
  - Modell: `BAAI/bge-small-en-v1.5`
  - Deployment Ã¼ber EC2 Auto Scaling Group (ASG)
  - Kostenoptimierte Skalierung: 0 Instanzen im Idle, auto-skalierend bei Last
  - Multiple Worker-Typen mÃ¶glich (z.B. small/large embedding models)
- **Create Lambda / Update Lambda / Delete Lambda**:
  - Schreiben/Updaten/LÃ¶schen der Embeddings in Pinecone
- **Pinecone** als Vektordatenbank
- **Optional**: RDS PostgreSQL fÃ¼r Rohdaten + S3 fÃ¼r Dateiuploads

### Infrastruktur

- Komplett via **Terraform** gebaut.
- CI/CD Pipelines mit **GitHub Actions**:
  - Lambdas (webhook, create, update, delete)
  - Embedding Worker (Docker Build + ECR Push)
  - Astro Frontend (S3 Sync + CloudFront Invalidate)
- Deployment getriggert per `paths` in GitHub Actions (nur bei Ã„nderungen)

### Monitoring & Logging

- **CloudWatch Logs** fÃ¼r alle Lambdas und EC2 Services.
- LogGroup Management Ã¼ber Terraform.
- Fehlerhafte Nachrichten Ã¼ber **DeadLetterQueues**.
- CloudWatch Alarme fÃ¼r Auto Scaling Trigger.

---

# ðŸ“Š Systemarchitektur Ãœbersicht (grafisch)

```mermaid
flowchart TD
    Client["Client"] -- HTTP POST Webhook --> APIGateway("API Gateway")
    APIGateway --> WebhookLambda("Webhook Lambda")
    WebhookLambda -- DELETE Event --> SQSDeleteQueue("SQS: DeleteQueue")
    WebhookLambda -- INSERT/UPDATE Event --> SQSChangeQueue("SQS: ChangeQueue")
    
    subgraph "Auto Scaling Group (0-N Instances)"
    EmbeddingWorker("Embedding Worker Service")
    end
    
    SQSChangeQueue -- Triggers ASG Scaling --> EmbeddingWorker
    EmbeddingWorker -- Vektorisiert --> SQSCreateQueue("SQS: CreateQueue") & SQSUpdateQueue("SQS: UpdateQueue")
    SQSCreateQueue --> CreateLambda("Create Lambda")
    SQSUpdateQueue --> UpdateLambda("Update Lambda")
    SQSDeleteQueue --> DeleteLambda("Delete Lambda")
    CreateLambda --> PineconeCreate["Pinecone: Insert New Chunks"]
    UpdateLambda --> PineconeUpdate["Pinecone: Replace Chunks"]
    DeleteLambda --> PineconeDelete["Pinecone: Delete by doc_hash"]
    WebhookLambda -- Optional: Save File --> S3("S3 Bucket")
```
---

# ðŸ”¢ Projektstruktur

```plaintext
/bloomweaver
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ api_gateway/
â”‚   â”œâ”€â”€ lambdas/
â”‚   â”‚   â”œâ”€â”€ webhook/
â”‚   â”‚   â”œâ”€â”€ create/
â”‚   â”‚   â”œâ”€â”€ update/
â”‚   â”‚   â”œâ”€â”€ delete/
â”‚   â”œâ”€â”€ sqs/
â”‚   â”‚   â”œâ”€â”€ change-queue/
â”‚   â”‚   â”œâ”€â”€ create-queue/
â”‚   â”‚   â”œâ”€â”€ update-queue/
â”‚   â”‚   â”œâ”€â”€ delete-queue/
â”‚   â”‚   â”œâ”€â”€ deadletter-queue/
â”‚   â”œâ”€â”€ ec2/
â”‚   â”‚   â”œâ”€â”€ auto_scaling_group/
â”‚   â”‚   â”œâ”€â”€ launch_template/
â”‚   â”‚   â”œâ”€â”€ scaling_policies/
â”‚   â”œâ”€â”€ s3_frontend/
â”‚   â”œâ”€â”€ s3_upload/
â”‚   â”œâ”€â”€ cloudfront/
â”‚   â”œâ”€â”€ rds/
â”œâ”€â”€ lambdas/
â”‚   â”œâ”€â”€ webhook/
â”‚   â”œâ”€â”€ create/
â”‚   â”œâ”€â”€ update/
â”‚   â”œâ”€â”€ delete/
â”œâ”€â”€ embedding-worker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ variants/
â”‚   â”‚   â”œâ”€â”€ small-model/
â”‚   â”‚   â”œâ”€â”€ large-model/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”œâ”€â”€ .github/
â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â”œâ”€â”€ lambda-webhook.yml
â”‚   â”‚   â”œâ”€â”€ lambda-create.yml
â”‚   â”‚   â”œâ”€â”€ lambda-update.yml
â”‚   â”‚   â”œâ”€â”€ lambda-delete.yml
â”‚   â”‚   â”œâ”€â”€ embedding-worker.yml
â”‚   â”‚   â”œâ”€â”€ frontend-deploy.yml
â”‚   â”‚   â”œâ”€â”€ terraform-apply.yml
```

---

# ðŸ“• Infrastruktur-Komponenten

## API Gateway + Webhook Lambda

- Validiert Webhook Calls.
- Delegiert je nach `change_type` (insert/update/delete) an entsprechende Queues.

## SQS Queues

- Entkoppeln die Verarbeitungsschritte.
- Retry Management durch DeadLetterQueues.
- Separate Queues fÃ¼r alle Operationstypen (Ã„ndern, Erstellen, Aktualisieren, LÃ¶schen).
- Trigger fÃ¼r EC2 Auto Scaling basierend auf Queue-Tiefe.

## Embedding Worker + Auto Scaling

- Splitten von Dokumenten.
- Embedding Generierung Ã¼ber Huggingface Transformers.
- Bereitstellung als REST API auf Docker-basierten EC2 Instanzen.
- Auto Scaling Group (ASG) mit:
  - MinSize=0, DesiredCapacity=0 (kein Idle-Betrieb)
  - MaxSize=5+ (skalierbar je nach Bedarf)
  - Scaling Policy basierend auf SQS Queue-Tiefe
  - Scale-Up bei 1-2+ Nachrichten
  - Scale-Down auf 0 nach 5 Minuten ohne Nachrichten
- Kostenoptimierung: Keine laufenden Instanzen bei keinem Traffic
- UnterstÃ¼tzung mehrerer Embedding Worker Varianten (z.B. fÃ¼r kleine vs. groÃŸe Modelle)
  - Via separate SQS Queues oder Message-Attribute

## Create/Update/Delete Lambdas

- Schreiben/Updaten/LÃ¶schen der Embeddings in Pinecone.
- Einhaltung der Konsistenz durch Doc-Hash Matching.
- Batch-Verarbeitung zur Optimierung der Operationen.

## Pinecone

- Speicherung der Vektor-ReprÃ¤sentationen.

## RDS + S3 (optional)

- Speicherung von Rohdaten oder originalen Dateien fÃ¼r spÃ¤tere Referenzierungen.

---

# ðŸš€ CI/CD Flows

- Webhook Lambda Build/Deploy
- Create Lambda Build/Deploy
- Update Lambda Build/Deploy
- Delete Lambda Build/Deploy
- Embedding Worker Docker Build + Push zu ECR
  - Varianten fÃ¼r verschiedene Embedding-Modelle
- Frontend Astro Build + Sync zu S3
- Terraform Apply nur bei Ã„nderung an Infrastruktur-Code

---

# ðŸ“ˆ Observability (Phase 1)

- CloudWatch Loggroups pro Service
- Fehlerauswertung Ã¼ber DeadLetter Queues
- CloudWatch Alarme fÃ¼r EC2 Auto Scaling
- Metriken fÃ¼r SQS Queue-Tiefe und Verarbeitungszeiten

---

# ðŸš€ Deployment Prozess (First Boot)

1. Terraform Infrastruktur aufbauen (terraform apply).
2. Webhook, Create, Update und Delete Lambdas bauen und hochladen.
3. Embedding Worker Docker Images bauen und nach ECR pushen.
4. EC2 Launch Template mit UserData Script fÃ¼r Auto-Deployment der Worker konfigurieren.
5. Auto Scaling Group und Scaling Policies einrichten.
6. Astro Frontend bauen und auf S3 synchronisieren.
7. CloudFront Distribution invalidieren.
8. Clerk einrichten fÃ¼r Frontend-Authentication.
9. API Gateway Endpoint an Client Ã¼bergeben.

---

# ðŸ”’ Security Best Practices

- IAM Rollen mit least-privilege.
- SQS Queues private.
- Pinecone API Keys sicher verwalten.
- Clerk fÃ¼r sichere Authentifizierung der User.
- SSL Ã¼berall aktiv.
- EC2 Instanzen in privaten Subnets mit Security Groups.

---

# ðŸš€ ErweiterungsplÃ¤ne

- Spezialisierte Embedding Worker auf GPU Nodes fÃ¼r komplexere Modelle.
- Multimodale Modelle (Text + Bilder).
- Admin Dashboard Ã¼ber Grafana Cloud.
- Automatische Chunk Optimierungen bei Dokumenten-Importen.
- API Gateway Rate Limits pro Kunde.
- Direkter Datenbank-Editor Ã¼ber das Admin Dashboard.
- Upload- und Datei-Editor direkt zum Projektstart.

---

# ðŸ‘‹ Kontakt

Projektleitung: Dennis Diepolder
Technische Leitung: Dennis Diepolder
Lizenz: Privat / Company Internal

---

> **Hinweis:** Dieses Projekt ist modular aufgebaut und kann jederzeit mit minimalem Aufwand um Logging, Monitoring, neue Features und neue Kundenquellen erweitert werden.

